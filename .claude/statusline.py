#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import sys, json, io, os

# UTF-8 ì…ì¶œë ¥ ì„¤ì •
if hasattr(sys.stdin, 'buffer'):
    sys.stdin = io.TextIOWrapper(sys.stdin.buffer, encoding='utf-8')
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')

# âœ… ì„¸ì…˜ í•œë„: 25ì‹œê°„(ìš”ì²­í•˜ì‹  5ë°°)
BLOCK_MS = 25 * 60 * 60 * 1000

def to_percent(v):
    if v is None:
        return None
    try:
        v = float(v)
    except Exception:
        return None
    if v <= 1.0:
        v *= 100.0
    return max(0.0, min(100.0, round(v, 1)))

def fmt_mmss(ms):
    if not isinstance(ms, (int, float)) or ms <= 0:
        return "0ë¶„"
    s = int(ms // 1000)
    h = s // 3600
    m = (s % 3600) // 60
    if h > 0:
        return f"{h}ì‹œê°„{m}ë¶„"
    return f"{m}ë¶„"

def fmt_tokens(n):
    """ì •ìˆ˜ í† í° ìˆ˜ë¥¼ ë³´ê¸° ì¢‹ê²Œ. 1000 ì´ìƒì€ k ë‹¨ìœ„(ì†Œìˆ˜1ìë¦¬)."""
    try:
        n = int(n)
    except Exception:
        return None
    if n < 1000:
        return str(n)
    return f"{n/1000:.1f}k"

def analyze_transcript(transcript_path):
    """transcript íŒŒì¼(.json ë˜ëŠ” .jsonl)ì„ ë¶„ì„í•˜ì—¬ í† í° ì‚¬ìš©ëŸ‰ ë° ì»¨í…ìŠ¤íŠ¸ ê³„ì‚°

    Returns:
        tuple: (total_input, total_output, context_tokens)
    """
    if not transcript_path or not os.path.exists(transcript_path):
        return None, None, None

    try:
        total_input = 0
        total_output = 0
        last_context_tokens = None

        # .jsonl í˜•ì‹ (JSON Lines) ì²˜ë¦¬
        if transcript_path.endswith('.jsonl'):
            with open(transcript_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    try:
                        entry = json.loads(line)
                        # message.usage êµ¬ì¡° í™•ì¸
                        msg = entry.get('message', {})
                        usage = msg.get('usage', {})
                        if isinstance(usage, dict):
                            input_tok = usage.get('input_tokens', 0) or 0
                            cache_read = usage.get('cache_read_input_tokens', 0) or 0
                            cache_create = usage.get('cache_creation_input_tokens', 0) or 0
                            output_tok = usage.get('output_tokens', 0) or 0

                            # ë¹„ìš© ì²­êµ¬ë˜ëŠ” í† í° = ìˆœìˆ˜ ì…ë ¥ + ìºì‹œ ìƒì„± (cache_readëŠ” ë¬´ë£Œ)
                            total_input += input_tok + cache_create
                            total_output += output_tok

                            # ë§ˆì§€ë§‰ ì‘ë‹µì˜ ì»¨í…ìŠ¤íŠ¸ í¬ê¸° (ì‹¤ì œ ì‚¬ìš©ëŸ‰)
                            if cache_read > 0 or cache_create > 0 or input_tok > 0:
                                last_context_tokens = input_tok + cache_read + cache_create
                    except:
                        continue
        else:
            # ì¼ë°˜ .json í˜•ì‹
            with open(transcript_path, 'r', encoding='utf-8') as f:
                transcript = json.load(f)

            messages = transcript.get('messages', [])
            for msg in messages:
                usage = msg.get('usage', {})
                if isinstance(usage, dict):
                    input_tok = usage.get('input_tokens', 0) or 0
                    cache_read = usage.get('cache_read_input_tokens', 0) or 0
                    cache_create = usage.get('cache_creation_input_tokens', 0) or 0
                    output_tok = usage.get('output_tokens', 0) or 0

                    # ë¹„ìš© ì²­êµ¬ë˜ëŠ” í† í° = ìˆœìˆ˜ ì…ë ¥ + ìºì‹œ ìƒì„± (cache_readëŠ” ë¬´ë£Œ)
                    total_input += input_tok + cache_create
                    total_output += output_tok

                    # ë§ˆì§€ë§‰ ì‘ë‹µì˜ ì»¨í…ìŠ¤íŠ¸ (ì‹¤ì œ ì‚¬ìš©ëŸ‰)
                    if cache_read > 0 or cache_create > 0 or input_tok > 0:
                        last_context_tokens = input_tok + cache_read + cache_create

        return (total_input if total_input > 0 else None,
                total_output if total_output > 0 else None,
                last_context_tokens)
    except Exception:
        return None, None, None

def load_stdin_json():
    try:
        # BOM ì œê±°ë¥¼ ìœ„í•´ í…ìŠ¤íŠ¸ë¡œ ì½ê¸°
        content = sys.stdin.read()
        # UTF-8 BOM ì œê±°
        if content.startswith('\ufeff'):
            content = content[1:]
        return json.loads(content)
    except Exception as e:
        return {}

data = load_stdin_json()

# --- ê¸°ë³¸ í•„ë“œ ---
model = data.get('model', {}).get('display_name', 'Unknown')
cost_usd = float(data.get('cost', {}).get('total_cost_usd', 0) or 0)
duration_ms = int(data.get('cost', {}).get('total_duration_ms', 0) or 0)
lines_add = int(data.get('cost', {}).get('total_lines_added', 0) or 0)
lines_del = int(data.get('cost', {}).get('total_lines_removed', 0) or 0)

# í”„ë¡œì íŠ¸ëª… ì¶”ì¶œ
workspace = data.get('workspace', {})
project_dir = workspace.get('project_dir') or workspace.get('current_dir') or data.get('cwd', '')
project_name = os.path.basename(project_dir) if project_dir else 'Unknown'

# --- ì„¸ì…˜ ì‚¬ìš©ë¥  - usage í•„ë“œê°€ ì œê³µë  ë•Œë§Œ í‘œì‹œ (í† í° ê¸°ë°˜) ---
usage = data.get('usage') or {}
session_used_pct = None
if isinstance(usage, dict):
    session_used_pct = to_percent((usage.get('session') or {}).get('percent_used'))

# ì‹œê°„ ê¸°ë°˜ fallback ì œê±° - usage í•„ë“œê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ
session_str = None
if session_used_pct is not None:
    session_str = f"{session_used_pct:.1f}%"

# --- í† í° ë¶„ì„: transcript.jsonì—ì„œ ì§ì ‘ ê³„ì‚° ---
transcript_path = data.get('transcript_path')
input_tokens, output_tokens, context_tokens = analyze_transcript(transcript_path)

# transcript ë¶„ì„ ì‹¤íŒ¨ ì‹œ fallback
if input_tokens is None and output_tokens is None:
    cost = data.get('cost') or {}
    token_counts = (cost.get('token_counts') or cost.get('tokens') or {}) if isinstance(cost, dict) else {}

    # ì…ë ¥ í† í° í›„ë³´
    for val in [cost.get('input_tokens'), cost.get('prompt_tokens'), token_counts.get('input'), usage.get('input_tokens')]:
        if val is not None:
            try:
                input_tokens = int(val)
                break
            except:
                pass

    # ì¶œë ¥ í† í° í›„ë³´
    for val in [cost.get('output_tokens'), cost.get('completion_tokens'), token_counts.get('output'), usage.get('output_tokens')]:
        if val is not None:
            try:
                output_tokens = int(val)
                break
            except:
                pass

# í† í° ë¬¸ìì—´ ìƒì„± (ì‚¬ìš©ì ê´€ì : in=ë°›ì€ê²ƒ, out=ë³´ë‚¸ê²ƒ)
total_tokens = (input_tokens or 0) + (output_tokens or 0) if (input_tokens is not None or output_tokens is not None) else None

if total_tokens is not None and total_tokens > 0:
    total_s = fmt_tokens(total_tokens)
    # ì‚¬ìš©ì ê´€ì ìœ¼ë¡œ swap:
    # in = AIë¡œë¶€í„° ë°›ì€ ê²ƒ (APIì˜ output_tokens)
    # out = AIì—ê²Œ ë³´ë‚¸ ê²ƒ (APIì˜ input_tokens)
    in_s = fmt_tokens(output_tokens) if output_tokens else "0"
    out_s = fmt_tokens(input_tokens) if input_tokens else "0"
    # íšŒìƒ‰ìœ¼ë¡œ í‘œì‹œ
    token_str = f"\033[90m{total_s} (in:{in_s}, out:{out_s})\033[0m"
else:
    token_str = "\033[90mn/a\033[0m"

# ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ ìƒì„± (200k ëŒ€ë¹„ ë‚¨ì€ ê³µê°„ %)
# ì£¼ì˜: transcriptì˜ cache_readëŠ” ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸/ë„êµ¬ë§Œ í¬í•¨í•˜ê³  MessagesëŠ” ì œì™¸ë¨
# ì‹œìŠ¤í…œ ì‚¬ìš©ëŸ‰(í”„ë¡¬í”„íŠ¸+ë„êµ¬ ì•½ 10%) ê¸°ë³¸ ì°¨ê°í•˜ì—¬ ë³´ì •
context_str = "\033[90mn/a\033[0m"
if context_tokens is not None and context_tokens > 0:
    # ì»¨í…ìŠ¤íŠ¸ í† í° 10% ë³´ì • ë° ì‹œìŠ¤í…œ ì‚¬ìš©ëŸ‰ 10% ì°¨ê°
    free_pct = ((200000 - (context_tokens * 1.1)) / 200000) * 100
    free_pct = max(0, free_pct - 10)
    # ìƒ‰ìƒ ê²°ì •: 50% ì´ìƒ = í°ìƒ‰, 50%~20% = ì˜¥ìƒ‰, 20% ì´í•˜ = í•«í•‘í¬
    if free_pct > 50:
        context_str = f"\033[97m{free_pct:.1f}%\033[0m"  # í°ìƒ‰ (ë°ì€ í°ìƒ‰)
    elif free_pct > 20:
        context_str = f"\033[96m{free_pct:.1f}%\033[0m"  # ì˜¥ìƒ‰ (ì‹œì•ˆ)
    else:
        context_str = f"\033[38;2;255;105;180m{free_pct:.1f}%\033[0m"  # í•«í•‘í¬ RGB(255, 105, 180)

# --- ì¶œë ¥ ---
# ì‹œê°„ ë¬¸ìì—´ (íšŒìƒ‰)
time_str = f"\033[90m{fmt_mmss(duration_ms)}\033[0m"
# ì†ŒìŠ¤ ë³€í™”ëŸ‰ ë¬¸ìì—´ (íšŒìƒ‰)
lines_str = f"\033[90m+{lines_add}/-{lines_del}\033[0m"

# ì„¸ì…˜ ì •ë³´ê°€ ìˆì„ ë•Œë§Œ í‘œì‹œ
session_part = f" | ğŸ”‹ {session_str}" if session_str is not None else ""

print(
    f"ğŸ“ \033[96m{project_name}\033[0m | ğŸ¤– {model} | â±ï¸ {time_str}{session_part} | ğŸ“¦ {context_str} | ğŸ”¢ {token_str} | ğŸ“ {lines_str}"
)
